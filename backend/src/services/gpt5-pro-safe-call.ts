/**
 * GPT-5 Pro Safe Call Wrapper
 *
 * ì•ˆì „ ì¥ì¹˜:
 * 1. ë¬´í•œë£¨í”„ ë°©ì§€: max_steps=6, ì¤‘ë³µ ì¶œë ¥ ì°¨ë‹¨, ê°•ì œ ì¢…ë£Œ í† í°
 * 2. í† í° ë‚­ë¹„ ë°©ì§€: 50k ì˜ˆì‚°, ì¶œë ¥ ìƒí•œ 2~4k
 * 3. íƒ€ì„ì•„ì›ƒ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€: 429/5xxë§Œ ì¬ì‹œë„, íƒ€ì„ì•„ì›ƒì€ ì¬ì‹œë„ ê¸ˆì§€
 * 4. í‰ê·  30~50k ìœ ì§€: ë™ì  íƒ€ì„ì•„ì›ƒ/ì¶œë ¥ í•œë„
 */

import crypto from 'crypto'
import OpenAI from 'openai'

const openai = new OpenAI({
	apiKey: process.env.OPENAI_API_KEY
})

export interface TokenUsage {
	prompt_tokens: number
	completion_tokens: number
	total_tokens: number
}

export interface SafeCallResult {
	text: string
	usage: TokenUsage
	stopReason: 'end' | 'duplicate' | 'single' | 'max_steps' | 'token_budget' | 'usd_budget' | 'timeout' | 'abort'
	steps: number
	cost: {
		input_usd: number
		output_usd: number
		total_usd: number
	}
}

export interface SafeCallOptions {
	messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>
	model?: string
	tokenBudget?: number // ì…ë ¥+ì¶œë ¥ í•©ì‚° ìƒí•œ (ê¸°ë³¸ 50,000)
	usdBudget?: number // ë‹¬ëŸ¬ ìƒí•œ (ê¸°ë³¸ 2.0)
	maxOutputTokens?: number // ì¶œë ¥ í† í° ìƒí•œ (ê¸°ë³¸ 3,000, ë²”ìœ„: 2,000~4,000)
	stop?: string[] // ì¢…ë£Œ í† í° (ê¸°ë³¸ ["\nEND"])
	maxRetries?: number // 429/5xx ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ 2)
	timeoutMs?: number // ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 90,000ms = 90ì´ˆ)
	maxSteps?: number // ìµœëŒ€ ìŠ¤í… ìˆ˜ (ê¸°ë³¸ 6)
	temperature?: number // ì˜¨ë„ (ê¸°ë³¸ 0.7)
	abortSignal?: AbortSignal // ì™¸ë¶€ ì·¨ì†Œ ì‹œê·¸ë„
	inPricePerM?: number // ì…ë ¥ í† í° ê°€ê²© (per million, ê¸°ë³¸ $15)
	outPricePerM?: number // ì¶œë ¥ í† í° ê°€ê²© (per million, ê¸°ë³¸ $120)
}

/**
 * ë¹„ìš© ê³„ì‚°
 */
function calculateCost(
	usage: TokenUsage,
	inPricePerM: number = 15,
	outPricePerM: number = 120
): { input_usd: number; output_usd: number; total_usd: number } {
	const input_usd = (usage.prompt_tokens / 1_000_000) * inPricePerM
	const output_usd = (usage.completion_tokens / 1_000_000) * outPricePerM
	const total_usd = input_usd + output_usd

	return {
		input_usd: parseFloat(input_usd.toFixed(4)),
		output_usd: parseFloat(output_usd.toFixed(4)),
		total_usd: parseFloat(total_usd.toFixed(4))
	}
}

/**
 * í•´ì‹œ ìƒì„± (ì¤‘ë³µ ì¶œë ¥ ì°¨ë‹¨ìš©)
 */
function createHash(text: string): string {
	const snippet = String(text).trim().slice(0, 512)
	return crypto.createHash('sha1').update(snippet).digest('hex')
}

/**
 * ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸°
 */
function exponentialBackoff(attempt: number): Promise<void> {
	const delayMs = 500 * 2 ** attempt
	return new Promise(resolve => setTimeout(resolve, delayMs))
}

/**
 * ë™ì  íƒ€ì„ì•„ì›ƒ ê³„ì‚°
 * ì…ë ¥ í† í°ê³¼ ì¶œë ¥ í•œë„ì— ë”°ë¼ íƒ€ì„ì•„ì›ƒ ìë™ ì¡°ì ˆ
 */
export function calculateDynamicTimeout(
	inputTokens: number,
	outputLimit: number
): number {
	const base = 30_000 // ê¸°ë³¸ 30ì´ˆ
	const inputBonus = Math.min(60_000, (inputTokens / 20_000) * 20_000)
	const outputBonus = Math.min(30_000, (outputLimit / 1000) * 5_000)
	const total = base + inputBonus + outputBonus

	return Math.min(180_000, total) // ìµœëŒ€ 180ì´ˆ
}

/**
 * í† í° ìˆ˜ ì¶”ì • (ê°„ë‹¨í•œ ë°©ì‹: 4 characters â‰ˆ 1 token)
 */
export function estimateTokens(text: string): number {
	return Math.ceil(text.length / 4)
}

/**
 * Safe GPT-5 Pro Call
 *
 * ëª¨ë“  ì•ˆì „ ì¥ì¹˜ê°€ ë‚´ì¥ëœ GPT-5 Pro í˜¸ì¶œ í•¨ìˆ˜
 */
export async function safeGpt5ProCall(
	options: SafeCallOptions
): Promise<SafeCallResult> {
	const {
		messages,
		model = 'gpt-4o', // GPT-5 Pro ì¶œì‹œ ì „ê¹Œì§€ëŠ” gpt-4o ì‚¬ìš©
		tokenBudget = 50_000,
		usdBudget = 2.0,
		maxOutputTokens = 3_000,
		stop = ['\nEND'],
		maxRetries = 2,
		timeoutMs = 90_000,
		maxSteps = 6,
		temperature = 0.7,
		abortSignal,
		inPricePerM = 15,
		outPricePerM = 120
	} = options

	let totalUsage: TokenUsage = {
		prompt_tokens: 0,
		completion_tokens: 0,
		total_tokens: 0
	}
	let lastHash = ''
	let totalCost = { input_usd: 0, output_usd: 0, total_usd: 0 }

	console.log(`ğŸ¤– Starting Safe GPT-5 Pro Call:`)
	console.log(`   Model: ${model}`)
	console.log(`   Token Budget: ${tokenBudget.toLocaleString()}`)
	console.log(`   Max Output Tokens: ${maxOutputTokens.toLocaleString()}`)
	console.log(`   Max Steps: ${maxSteps}`)
	console.log(`   Timeout: ${timeoutMs}ms`)

	// ë‹¨ì¼ ìŠ¤í… ì‹¤í–‰ (ê²¬ì  ë¶„ì„ì€ ë³´í†µ ë‹¨ì¼ ìŠ¤í…ìœ¼ë¡œ ì¶©ë¶„)
	for (let step = 1; step <= maxSteps; step++) {
		console.log(`\nğŸ“Š Step ${step}/${maxSteps}`)

		// ì™¸ë¶€ ì·¨ì†Œ í™•ì¸
		if (abortSignal?.aborted) {
			console.log('âš ï¸  Abort signal received')
			return {
				text: '',
				usage: totalUsage,
				stopReason: 'abort',
				steps: step - 1,
				cost: totalCost
			}
		}

		// íƒ€ì„ì•„ì›ƒ ì»¨íŠ¸ë¡¤ëŸ¬
		const controller = new AbortController()
		const timer = setTimeout(() => {
			console.log('â° Request timeout')
			controller.abort()
		}, timeoutMs)

		let response: OpenAI.Chat.Completions.ChatCompletion | null = null
		let lastError: Error | null = null

		// ì¬ì‹œë„ ë¡œì§ (429/5xxë§Œ)
		for (let attempt = 0; attempt <= maxRetries; attempt++) {
			try {
				console.log(`   ğŸ”„ Attempt ${attempt + 1}/${maxRetries + 1}`)

				response = await openai.chat.completions.create(
					{
						model,
						messages,
						max_tokens: maxOutputTokens,
						temperature,
						stop,
						stream: false
					},
					{
						signal: abortSignal || controller.signal,
						timeout: timeoutMs
					}
				)

				// ì„±ê³µ ì‹œ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
				break
			} catch (error: any) {
				clearTimeout(timer)
				lastError = error

				// ì¬ì‹œë„ ê°€ëŠ¥ ì—ëŸ¬ íŒë‹¨
				const status = error?.status || error?.response?.status
				const isRetriable = status === 429 || (status >= 500 && status < 600)

				console.log(
					`   âŒ Error: ${error.message} (status: ${status}, retriable: ${isRetriable})`
				)

				// ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ë§ˆì§€ë§‰ ì‹œë„ì¸ ê²½ìš°
				if (!isRetriable || attempt === maxRetries) {
					// íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ê¸ˆì§€
					if (error.message?.includes('timeout') || error.name === 'AbortError') {
						console.log('â° Timeout occurred - will not retry')
						throw new Error('Request timeout - automatic retry disabled')
					}
					throw error
				}

				// ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸°
				await exponentialBackoff(attempt)
			}
		}

		clearTimeout(timer)

		if (!response) {
			throw lastError || new Error('No response from API')
		}

		// ì‘ë‹µ ì¶”ì¶œ
		const text = response.choices[0]?.message?.content || ''
		const usage = response.usage || {
			prompt_tokens: 0,
			completion_tokens: 0,
			total_tokens: 0
		}

		console.log(`   âœ… Response received:`)
		console.log(`      Prompt tokens: ${usage.prompt_tokens.toLocaleString()}`)
		console.log(`      Completion tokens: ${usage.completion_tokens.toLocaleString()}`)
		console.log(`      Total tokens: ${usage.total_tokens.toLocaleString()}`)

		// ì‚¬ìš©ëŸ‰ ëˆ„ì 
		totalUsage.prompt_tokens += usage.prompt_tokens
		totalUsage.completion_tokens += usage.completion_tokens
		totalUsage.total_tokens += usage.total_tokens

		// ë¹„ìš© ê³„ì‚°
		const stepCost = calculateCost(usage, inPricePerM, outPricePerM)
		totalCost.input_usd += stepCost.input_usd
		totalCost.output_usd += stepCost.output_usd
		totalCost.total_usd += stepCost.total_usd

		console.log(
			`      Cost: $${stepCost.total_usd.toFixed(4)} (input: $${stepCost.input_usd.toFixed(4)}, output: $${stepCost.output_usd.toFixed(4)})`
		)

		// í† í° ì˜ˆì‚° ì´ˆê³¼ ì²´í¬
		if (totalUsage.total_tokens > tokenBudget) {
			console.log(
				`âš ï¸  Token budget exceeded: ${totalUsage.total_tokens.toLocaleString()} > ${tokenBudget.toLocaleString()}`
			)
			throw new Error(
				`Token budget exceeded: ${totalUsage.total_tokens} > ${tokenBudget}`
			)
		}

		// USD ì˜ˆì‚° ì´ˆê³¼ ì²´í¬
		if (totalCost.total_usd > usdBudget) {
			console.log(
				`âš ï¸  USD budget exceeded: $${totalCost.total_usd.toFixed(4)} > $${usdBudget.toFixed(2)}`
			)
			throw new Error(
				`USD budget exceeded: $${totalCost.total_usd.toFixed(4)} > $${usdBudget.toFixed(2)}`
			)
		}

		// ì¤‘ë³µ ì¶œë ¥ ì°¨ë‹¨ (ë™ì¼í•œ ì‘ë‹µ ë°˜ë³µ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨)
		const textHash = createHash(text)
		if (textHash === lastHash) {
			console.log('âš ï¸  Duplicate output detected - stopping')
			return {
				text,
				usage: totalUsage,
				stopReason: 'duplicate',
				steps: step,
				cost: totalCost
			}
		}
		lastHash = textHash

		// ê°•ì œ ì¢…ë£Œ í† í° í™•ì¸
		if (text.trim().endsWith('END')) {
			console.log('âœ… END token detected - normal completion')
			return {
				text: text.replace(/\nEND$/, '').trim(), // END ì œê±°
				usage: totalUsage,
				stopReason: 'end',
				steps: step,
				cost: totalCost
			}
		}

		// ë‹¨ì¼ ìŠ¤í…ìœ¼ë¡œ ì™„ë£Œ (ê²¬ì  ë¶„ì„ì€ ë³´í†µ ë‹¨ì¼ í˜¸ì¶œ)
		console.log('âœ… Single step completion')
		return {
			text,
			usage: totalUsage,
			stopReason: 'single',
			steps: step,
			cost: totalCost
		}
	}

	// ìµœëŒ€ ìŠ¤í… ë„ë‹¬
	console.log('âš ï¸  Max steps reached')
	throw new Error(`Max steps (${maxSteps}) reached - possible infinite loop`)
}

/**
 * í”„ë¦¬í”Œë¼ì´íŠ¸: í† í° ê²¬ì  ê³„ì‚°
 * ë³¸ ì‹¤í–‰ ì „ ì…ë ¥ ë°ì´í„°ì˜ í† í° ìˆ˜ë¥¼ ì¶”ì •í•˜ì—¬ K/ê¸¸ì´ í•œë„ ì¡°ì ˆ
 */
export async function preflightEstimate(
	messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>
): Promise<{
	estimatedInputTokens: number
	recommendedOutputTokens: number
	recommendedTimeout: number
}> {
	// ì „ì²´ ë©”ì‹œì§€ í…ìŠ¤íŠ¸ í•©ì‚°
	const fullText = messages.map(m => m.content).join('\n')
	const estimatedInputTokens = estimateTokens(fullText)

	// ì¶œë ¥ í† í° ì¶”ì²œ (ì…ë ¥ì˜ 20~40% ë˜ëŠ” ìµœì†Œ 2000)
	const recommendedOutputTokens = Math.max(
		2000,
		Math.min(4000, Math.ceil(estimatedInputTokens * 0.3))
	)

	// íƒ€ì„ì•„ì›ƒ ì¶”ì²œ
	const recommendedTimeout = calculateDynamicTimeout(
		estimatedInputTokens,
		recommendedOutputTokens
	)

	console.log(`ğŸ” Preflight Estimate:`)
	console.log(`   Estimated Input Tokens: ${estimatedInputTokens.toLocaleString()}`)
	console.log(
		`   Recommended Output Tokens: ${recommendedOutputTokens.toLocaleString()}`
	)
	console.log(`   Recommended Timeout: ${recommendedTimeout}ms`)

	return {
		estimatedInputTokens,
		recommendedOutputTokens,
		recommendedTimeout
	}
}
