/**
 * Image Parser Service
 *
 * Uses Google Cloud Vision API for OCR + GPT-5 for structuring
 * Includes image optimization to reduce storage costs
 */

import vision from '@google-cloud/vision'
import OpenAI from 'openai'
import { optimizeImage } from './image-optimizer'

interface ParsedQuoteItem {
	category: string
	item: string
	quantity: number
	unit: string
	unit_price: number
	total_price: number
	notes?: string
}

interface ImageParseResult {
	items: ParsedQuoteItem[]
	success: boolean
	message?: string
	optimizedImage?: Buffer // Compressed image to save
	thumbnail?: Buffer // Thumbnail for list view
	compressionStats?: {
		originalSize: number
		compressedSize: number
		compressionRatio: number
	}
}

/**
 * Parse quote image using Google Vision (OCR) + GPT-5 (structuring)
 * More cost-effective than using vision-only models
 */
export async function parseQuoteImage(imageBuffer: Buffer): Promise<ImageParseResult> {
	try {
		const OPENAI_API_KEY = process.env.OPENAI_API_KEY
		const GOOGLE_API_KEY = process.env.GOOGLE_CLOUD_API_KEY

		if (!GOOGLE_API_KEY && !process.env.GOOGLE_APPLICATION_CREDENTIALS) {
			console.error('âš ï¸  Google Cloud credentials not found')
			return {
				success: false,
				items: [],
				message: 'Google Cloud Vision API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
			}
		}

		if (!OPENAI_API_KEY) {
			console.error('âš ï¸  OPENAI_API_KEY not found')
			return {
				success: false,
				items: [],
				message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
			}
		}

		// Initialize OpenAI client
		const openai = new OpenAI({
			apiKey: OPENAI_API_KEY
		})

		// Step 1: Optimize image first (compress and resize)
		console.log('ðŸ“¦ Optimizing image before OCR...')
		const optimized = await optimizeImage(imageBuffer, {
			maxWidth: 1920,
			quality: 80,
			thumbnailSize: 200,
			format: 'jpeg'
		})

		// Step 2: Extract text using Google Cloud Vision API (OCR)
		console.log('ðŸ” Performing OCR with Google Cloud Vision API...')

		const client = new vision.ImageAnnotatorClient({
			apiKey: GOOGLE_API_KEY
		})

		const [result] = await client.textDetection(optimized.compressed)
		const detections = result.textAnnotations

		if (!detections || detections.length === 0) {
			return {
				success: false,
				items: [],
				message: 'ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
			}
		}

		// The first annotation contains all detected text
		const extractedText = detections[0]?.description || ''

		if (!extractedText.trim()) {
			return {
				success: false,
				items: [],
				message: 'í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
			}
		}

		console.log('ðŸ“ Extracted text length:', extractedText.length)
		console.log('ðŸ“„ Sample text:', extractedText.substring(0, 200))

		// Step 3: Structure the extracted text using GPT-5 (cost-effective and accurate)
		console.log('ðŸ¤– Structuring data with GPT-5...')

		const completion = await openai.chat.completions.create({
			model: 'gpt-5',
			messages: [
				{
					role: 'system',
					content: 'ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ì‹œê³µ ê²¬ì ì„œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ êµ¬ì¡°í™”ëœ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.'
				},
				{
					role: 'user',
					content: `ë‹¤ìŒì€ ê²¬ì ì„œ ì´ë¯¸ì§€ì—ì„œ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ìž…ë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œê³µ í•­ëª©ì„ ì¶”ì¶œí•˜ê³  JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.

ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
${extractedText}

ë°˜í™˜ í˜•ì‹:
{
  "items": [
    {
      "category": "ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ì² ê±°, ëª©ê³µ, ë„ë°°, íƒ€ì¼, ì „ê¸°, ë°°ê´€ ë“±)",
      "item": "êµ¬ì²´ì ì¸ í•­ëª©ëª…",
      "quantity": ìˆ˜ëŸ‰(ìˆ«ìž),
      "unit": "ë‹¨ìœ„ (ì˜ˆ: í‰, ê°œ, m ë“±)",
      "unit_price": ë‹¨ê°€(ìˆ«ìž),
      "total_price": ì´ì•¡(ìˆ«ìž),
      "notes": "ë¹„ê³  (ì„ íƒì‚¬í•­)"
    }
  ]
}

ì£¼ì˜ì‚¬í•­:
- ëª¨ë“  ìˆ«ìžëŠ” ì‰¼í‘œ ì—†ì´ ìˆœìˆ˜ ìˆ«ìžë¡œ ë³€í™˜
- ì¹´í…Œê³ ë¦¬ëŠ” ì¼ë°˜ì ì¸ ì¸í…Œë¦¬ì–´ ë¶„ë¥˜ ì‚¬ìš© (ì² ê±°, ëª©ê³µ, ë„ë°°, íƒ€ì¼, ì „ê¸°, ë°°ê´€, íŽ˜ì¸íŠ¸, ì£¼ë°©, ìš•ì‹¤, ë°”ë‹¥, ì°½í˜¸ ë“±)
- í•­ëª©ëª…ì€ êµ¬ì²´ì ìœ¼ë¡œ ìž‘ì„±
- ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì •í•˜ì§€ ë§ê³  ë¹„ì›Œë‘ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
- JSONë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”`
				}
			],
			max_tokens: 4096,
			temperature: 0.0, // ì •í™•ë„ ìš°ì„ 
			response_format: { type: 'json_object' } // JSON ëª¨ë“œ í™œì„±í™”
		})

		const content = completion.choices[0]?.message?.content

		if (!content) {
			throw new Error('GPT-5 API ì‘ë‹µì´ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.')
		}

		console.log('ðŸ“ GPT-5 Response:', content)

		// Parse JSON response
		let jsonContent = content.trim()
		if (jsonContent.startsWith('```json')) {
			jsonContent = jsonContent.replace(/^```json\n/, '').replace(/\n```$/, '')
		} else if (jsonContent.startsWith('```')) {
			jsonContent = jsonContent.replace(/^```\n/, '').replace(/\n```$/, '')
		}

		const parsed = JSON.parse(jsonContent)

		if (!parsed.items || !Array.isArray(parsed.items)) {
			throw new Error('ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.')
		}

		// Validate and clean items
		const cleanedItems: ParsedQuoteItem[] = parsed.items.map((item: any) => ({
			category: String(item.category || 'ê¸°íƒ€'),
			item: String(item.item || ''),
			quantity: Number(item.quantity) || 1,
			unit: String(item.unit || 'ê°œ'),
			unit_price: Number(item.unit_price) || 0,
			total_price: Number(item.total_price) || 0,
			notes: item.notes ? String(item.notes) : undefined
		}))

		console.log(`âœ… Successfully parsed ${cleanedItems.length} items from image`)

		return {
			success: true,
			items: cleanedItems,
			optimizedImage: optimized.compressed,
			thumbnail: optimized.thumbnail,
			compressionStats: {
				originalSize: optimized.originalSize,
				compressedSize: optimized.compressedSize,
				compressionRatio: optimized.compressionRatio
			}
		}
	} catch (error) {
		console.error('Image parsing error:', error)
		return {
			success: false,
			items: [],
			message: error instanceof Error ? error.message : 'Unknown error'
		}
	}
}
